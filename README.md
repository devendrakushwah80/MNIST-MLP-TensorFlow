# ğŸ§  MNIST Digit Classification using Deep MLP (TensorFlow)

This project implements a Deep Multi-Layer Perceptron (MLP) model using TensorFlow to classify handwritten digits from the MNIST dataset.

---

## ğŸ“Œ Project Overview

- Dataset: MNIST (Handwritten digits 0â€“9)
- Framework: TensorFlow / Keras
- Model Type: Deep Neural Network (MLP)
- Input Shape: 784 (28x28 flattened)
- Output Classes: 10
- Optimizer: Adam
- Loss Function: Sparse Categorical Crossentropy

---

## ğŸ“‚ Dataset

The MNIST dataset contains:
- 60,000 training images
- 10,000 testing images
- Grayscale images (28x28 pixels)

Loaded using:

```python
tf.keras.datasets.mnist.load_data()
```
ğŸ”„ Data Preprocessing

Reshaped images from (28,28) â†’ (784,)

Normalized pixel values (0â€“255 â†’ 0â€“1)

x_train = x_train.reshape(-1, 784) / 255.0
x_test = x_test.reshape(-1, 784) / 255.0
ğŸ— Model Architecture
Layer	Units	Activation
Dense	256	ReLU
Dense	128	ReLU
Dense	64	ReLU
Dense	10	Softmax
âš™ Model Compilation
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
ğŸ‹ Training

Epochs: 10

Batch Size: 32

Validation Split: 20%

ğŸ“Š Evaluation Metrics

Accuracy

Classification Report (Precision, Recall, F1-score)

Confusion Matrix (Heatmap)

Training vs Validation Accuracy Graph

ğŸ“ˆ Results

High training and validation accuracy

Clear digit classification with minimal misclassification

Strong performance without using CNN
ğŸ“¦ Requirements

Install dependencies:

pip install -r requirements.txt
â–¶ How to Run

Clone the repository

Install requirements

Open Jupyter Notebook

Run MLP_Tf.ipynb

ğŸ¯ Future Improvements

Add Dropout layers

Add EarlyStopping

Convert to CNN for better performance

Add model saving & loading

Deploy with Streamlit

ğŸ‘¨â€ğŸ’» Author

Devendra Kushwah
